
 -  [NVIDIA Deep Learning Institute](https://learn.nvidia.com/) - Education and training solutions to solve the world’s greatest challenges
     -  [Learning Paths for Developers and Administrators](https://nvdam.widen.net/s/brxsxxtskb/dli-learning-journey-2009000-r5-web). \[[PDF](https://nvdam.widen.net/content/jq9sci1t4t/original/dli-learning-journey-2009000-r5-web.pdf)\]
     -  [Course Detail](https://learn.nvidia.com/courses/course-detail) - 這個免費課程有證書可以拿哦 :-)
 -  [Learn New Technical Skills](https://developer.nvidia.com/join-nvidia-developer-program) - Free NVIDIA Deep Learning Institute (DLI) courses for beginners. 

---

# [NVIDIA 免費 AI 線上課程](https://twitter.com/heyshrutimishra/status/1771206798881825005)

## Part 1

 -  [Generative AI Explained / 解釋生成式 AI](https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+S-FX-07+V1)

    課程內容：
     -  生成式 AI 的定義、工作原理
     -  各種生成式 AI 應用
     -  生成式 AI 的挑戰和機會

    課前要求：對機器學習和深度學習有基本的瞭解。

 -  [Building A Brain in 10 Minutes / 10 分鐘內構建「大腦」](https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+T-FX-01+V1)

    課程內容：
     -  神經網路如何使用資料進行學習
     -  神經元背後的數學原理

    課前要求：
     -  瞭解 Python 3 中的基本程式設計概念，如函式、迴圈、字典和陣列；
     -  瞭解如何計算迴歸線。

 -  [Augment your LLM Using Retrieval Augmented Generation / 使用 RAG 增強 LLM 性能](https://learn.nvidia.com/courses/course-detail?course_id=course-v1:NVIDIA+S-FX-16+v1)

    課程內容：
     -  RAG 基礎知識
     -  RAG 檢索過程
     -  NVIDIA AI 基礎和 RAG 模型元件

 -  [Building RAG Agents with LLMs / 使用 LLM 構建 RAG 智慧體](https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+S-FX-15+V1)

    課程內容：
     -  探索 LLM 和向量資料庫的可擴充套件部署策略
     -  學習微服務知識，掌握如何在微服務之間協作以及如何開發屬於自己的微服務
     -  利用 LangChain 正規化來開發對話管理和文件檢索解決方案
     -  用最先進的模型練習，明確有關產品化和框架探索的後續步驟

    適合熟悉 LLM 及其相關組合框架 (如 LangChain)，具有中級 Python 水準，最好具備網路工程和開發維運背景。

 -  [Accelerate Data Science Workflows with Zero Code Changes / 零程式碼更改加速資料科學工作流](https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+T-DS-03+V1)

    課程內容：
     -  瞭解跨 CPU 和 GPU 的制式工作流在資料科學任務中的優勢
     -  學習如何在不更改程式碼的情況下，利用 GPU 加速各種資料處理和機器學習工作流程
     -  體驗當工作流程透過 GPU 加速時，處理時間顯著縮短的效果

    課前要求：
     -  對表格資料上的資料處理和標準資料科學工作流程有基本的理解
     -  有使用常見 Python 資料分析庫的經驗
     -  使用過 NVIDIA RAPIDS (cuDF, cuML, cuGraph)、pandas、scikit-learn 和 NetworkX
    
 -  [How to Perform Large-Scale Image Classification / 如何進行大規模影像分類](https://www.classcentral.com/course/youtube-grandmaster-series-how-to-perform-large-scale-image-classification-130184)

    課程內容：如何進行大規模影像分類，涵蓋挑戰、建模技術和驗證策略。

    適合資料科學家、機器學習從業者以及對深度學習感興趣的人觀看。

 -  [Mastering Recommender Systems / 掌握推薦系統](https://www.classcentral.com/course/youtube-grandmaster-series-mastering-recommender-systems-184298)

    課程內容：NVIDIA Kaggle Grandmasters 構建電子商務推薦系統的策略， 內容涵蓋 2 階段模型、候選模型生成、特徵工程和整合方法。

    適合資料科學家、機器學習工程師以及對推薦系統和資料科學感興趣的人觀看。

 -  [Introduction to AI in the Data Center / 資料中心的 AI](https://www.coursera.org/learn/introduction-ai-data-center)

    課程內容：
     -  AI 案例、機器學習、深度學習及其工作流程
     -  GPU 架構及其對 AI 的影響
     -  深度學習框架和部署注意事項

 -  [Introduction to Networking / 網路技術入門](https://www.coursera.org/learn/introduction-to-networking-nvidia)

    課程內容：
     -  瞭解網路及其重要性。
     -  探索乙太網基礎知識及乙太網網路中的資料轉發。
     -  討論網路元件、需求、OSI 模型、TCP/IP 協議。

## Part 2

 -  [Mastering GitHub Copilot for AI Paired Programming](https://github.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming)
 -  [Multi GPU Programming Models](https://github.com/NVIDIA/multi-gpu-programming-models) 
 -  [nvCOMP docs and examples](https://github.com/NVIDIA/nvcomp)
 -  NVIDIA AI Workbench
     -  [How to customize a Stable Diffusion XL (SDXL) model](https://github.com/NVIDIA/workbench-example-sdxl-customization)
     -  [How to fine-tune a Llama v2 7B large language model](https://github.com/NVIDIA/workbench-example-llama2-finetune)
     -  [How to p-tune and prompt tune a NeMo-Megatron LLM using the NeMo Framework](https://github.com/NVIDIA/workbench-example-nemo-ptuning)
     -  [How to train a Large Language Model to annotate large sections of text with realistic punctuation and capitalization using the NeMo Framework](https://github.com/NVIDIA/workbench-example-nemo-punctuation)
     -  [Short introduction of the cuDF library](https://github.com/NVIDIA/workbench-example-rapids-cudf)
     -  [Short introduction of the cuML library](https://github.com/NVIDIA/workbench-example-rapids-cuml)
 -  [NVIDIA BioNeMo Examples](https://github.com/NVIDIA/BioNeMo)
 -  [NVIDIA Deep Learning Examples for Tensor Cores](https://github.com/NVIDIA/DeepLearningExamples)
 -  [NVIDIA Generative AI Examples](https://github.com/NVIDIA/GenerativeAIExamples)
 -  [NVIDIA Grace CPU Benchmarking Guide](https://github.com/NVIDIA/grace-cpu-benchmarking-guide)
 -  [OptiX Toolkit (OTK) Examples](https://github.com/NVIDIA/otk-examples)
 -  [RAPIDS Accelerator for Apache Spark examples](https://github.com/NVIDIA/spark-rapids-examples)

---

# My Collection

 -  [100 Days of ML Coding](https://github.com/Avik-Jain/100-Days-Of-ML-Code)
 -  [RAG using Llama 3 by Meta AI](https://lightning.ai/lightning-ai/studios/rag-using-llama-3-by-meta-ai?tab=overview)\
    In this studio we are building a completely self-hosted "Chat with your Docs" RAG application using Llama-3, served locally through Ollama.
 -  [RAG Techniques](https://github.com/NirDiamant/RAG_Techniques)\
    內容涵蓋各種先進的 RAG 技術，採用範例程式碼（LangChain、LlamaIndex）來詳細解說每個技術的核心概念
 -  [GenAI Agents](https://github.com/NirDiamant/GenAI_Agents)\
    提供了從基礎到高級的各種生成式 AI 代理技術的教學和實作
 -  [Transformers Tutorials](https://github.com/NielsRogge/Transformers-Tutorials)\
    這份線上教學手冊是 Niels Rogge 所收集的 40 多種各式各樣的任務模型/演算法的程式範例
 -  [Umar Jamil 的機器學習教學影片](https://github.com/nqobu/nvidia/blob/main/tutorials/Umar%20Jamil.md)
 -  [Ilya Sutskever 的機器學習推薦清單](https://github.com/nqobu/nvidia/blob/main/tutorials/Ilya%20Sutskever.md)

## LLMs

 -  [Stanford CS229 | Machine Learning | Building Large Language Models (LLMs)](https://youtu.be/9vM4p9NN0Ts)
 -  [LLM Twin Course: Building Your Production-Ready AI Replica](https://github.com/decodingml/llm-twin-course)
 -  [End-to-end LLM Workflows Guide](https://www.anyscale.com/blog/end-to-end-llm-workflows-guide)
 -  [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)
 -  [A Comprehensive Overview of Large Language Models](https://arxiv.org/abs/2307.06435)
 -  [A Comprehensive Survey of LLM Alignment Techniques: RLHF, RLAIF, PPO, DPO and More](https://arxiv.org/abs/2407.16216)
 -  [Foundational Challenges in Assuring Alignment and Safety of Large Language Models](https://arxiv.org/abs/2404.09932)
 -  [Awesome Generative AI Guide](https://github.com/aishwaryanr/awesome-generative-ai-guide)
 -  [OpenAI Cookbook](https://github.com/openai/openai-cookbook)
 -  The three-part series on how Imbue trained their 70B model
     -  [Training a 70B model from scratch: open-source tools, evaluation datasets, and learnings](https://imbue.com/research/70b-intro/)
     -  [Sanitized open-source datasets for natural language and code understanding: how we evaluated our 70B model](https://imbue.com/research/70b-evals/)
     -  [From bare metal to a 70B model: infrastructure set-up and scripts](https://imbue.com/research/70b-infrastructure/)
     -  [Open-sourcing CARBS: how we used our hyperparameter optimizer to scale up to a 70B-parameter language model](https://imbue.com/research/70b-carbs/)
 -  [Andrej Karpathy](https://www.youtube.com/@AndrejKarpathy)
     -  [llm.c](https://github.com/karpathy/llm.c) - LLM training in simple, raw C/CUDA
     -  [llama2.c](https://github.com/karpathy/llama2.c) - Inference Llama 2 in one file of pure C
     -  [nanoGPT](https://github.com/karpathy/nanoGPT) - The simplest, fastest repository for training/finetuning medium-sized GPTs

Misc.

 -  [NVIDIA NIM](https://www.nvidia.com/en-us/ai/)
 -  [NVIDIA NeMo](https://www.nvidia.com/en-us/ai-data-science/products/nemo/)
 -  [NeMo: a toolkit for building AI applications using Neural Modules](https://arxiv.org/abs/1909.09577)
 -  [ChipNeMo: Domain-Adapted LLMs for Chip Design](https://arxiv.org/abs/2311.00176)
     -  See also: [SemiKong](https://www.semikong.ai/) and [SemiKong's github](https://github.com/aitomatic/semikong)
<!--
# Performance

**ChipNeMo**

Demonstrates improved performance over baseline models like LLaMA2 across various benchmarks. For instance, ChipNeMo-13B outperforms LLaMA2-13B in several metrics such as MMLU, Reason Code, and others, indicating its effectiveness in adapting to domain-specific tasks like chip design

 -  **Architecture**: ChipNeMo is designed for efficient chip-level neural network model design and optimization. It provides advanced algorithms to improve the accuracy and efficiency of chip designs.
 -  **Optimization**: ChipNeMo integrates with various optimization techniques for both chip design and neural network training, aiming to enhance performance in specific hardware contexts.
 -  **Scalability**: The focus is on scalability and customization for different chip architectures, potentially offering high performance for specific tasks.

**SemiKong**

While specific performance metrics for SemiKong are not provided, similar tools often focus on providing accurate and efficient solutions for their intended domains. Performance would typically be evaluated against industry standards, competitor products, or custom benchmarks relevant to the tool's application area.

 -  **Architecture**: SemiKong is a platform designed to optimize the performance of semiconductors and related technologies. It leverages AI and machine learning for chip design and performance analysis.
 -  **Optimization**: Provides tools for improving semiconductor design and testing, with a focus on enhancing the performance of semiconductor devices.
 -  **Scalability**: Targets broad applications within the semiconductor industry, potentially offering high performance across a range of semiconductor technologies.

# Usability

**ChipNeMo**

Offers enhanced usability through features like automatic generation of EDA scripts and bug summarization and analysis, which are crucial for chip design tasks. These functionalities aim to streamline the workflow for users dealing with complex chip designs.

 -  **Target Users**: Typically used by engineers and researchers specializing in chip design and hardware optimization.
 -  **Complexity**: ChipNeMo might require a deep understanding of both neural network principles and chip design to effectively utilize its features.

**SemiKong**

Usability would likely involve ease of integration into existing workflows, intuitive interfaces for non-experts, and comprehensive documentation. Tools in this space often prioritize user experience to facilitate adoption and effective problem-solving.

 -  **Target Users**: Aimed at semiconductor engineers, designers, and researchers working on semiconductor technology and chip design.
 -  **Complexity**: Offers tools that may be more user-friendly with a focus on practical applications in semiconductor design, potentially making it more accessible to users less specialized in neural network design.

# Features

**ChipNeMo**

Incorporates domain-adapted large language models (LLMs) specifically tailored for chip design, leveraging techniques like tokenizer augmentation and parameter-efficient fine-tuning. This specialization allows ChipNeMo to handle domain-specific tasks more effectively

 -  **Integration**: It integrates with existing EDA (Electronic Design Automation) tools, providing a seamless workflow for chip design.
 -  **Customization**: Offers specialized tools for customizing and optimizing neural networks for specific chip architectures.
 -  **Focus**: Primarily focused on the intersection of hardware design and neural network optimization.

**SemiKong**

Features would typically align with the tool's purpose, whether it's simulation, optimization, verification, or another aspect of chip design. Common features might include support for various file formats, integration with popular EDA tools, and advanced analytics capabilities.

 -  **Platform Integration**: Provides a comprehensive platform with tools for design, simulation, and testing of semiconductor devices.
 -  **AI Integration**: Utilizes AI to optimize semiconductor performance, offering advanced analytics and insights.
 -  **Focus**: Broad focus on the semiconductor industry with tools tailored for various aspects of semiconductor design and optimization.

# Key Differences

 -  **Specialization vs. Generalization**: ChipNeMo is specialized for chip design, incorporating domain-specific adaptations to enhance performance on related tasks. SemiKong, while not explicitly described, would likely offer a broader set of features or applications outside the narrow scope of chip design.
 -  **Performance Metrics**: ChipNeMo demonstrates superior performance in several benchmarks relevant to chip design, suggesting it may outperform SemiKong in these specific areas unless SemiKong has been optimized for similar tasks.
 -  **Usability and Integration**: Both tools would aim for high usability, but ChipNeMo's focus on automating specific aspects of chip design could make it more appealing for users looking for streamlined processes. SemiKong's approach might differ, focusing on broader applicability or integration capabilities.

# Summary

ChipNeMo stands out for its specialized performance in chip design tasks, thanks to its domain-adapted LLMs and innovative features like automatic script generation and bug analysis. Without explicit details on SemiKong, it's challenging to make a direct comparison, but typical tools in this space would compete on features, performance, and usability, potentially offering a broader range of applications or easier integration into existing workflows.

 -  **Usability and Integration**: Both tools would aim for high usability, but ChipNeMo's focus on automating specific aspects of chip design could make it more appealing for users looking for streamlined processes. SemiKong's approach might differ, focusing on broader applicability or integration capabilities.
 -  **ChipNeMo** is specialized for optimizing neural networks in the context of chip design, focusing on high performance for specific chip architectures and requiring a good grasp of both neural network and hardware concepts.
 -  **SemiKong** provides a broader platform for semiconductor design and optimization, integrating AI for performance improvements and being potentially more accessible to a wider range of users in the semiconductor field.
  -->
 -  [LLM Engineer's Handbook: Master the art of engineering Large Language Models from concept to production](https://www.amazon.com/dp/1836200072)
 -  [Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)
 -  [Understanding Large Language Models: Towards Rigorous and Targeted Interpretability Using Probing Classifiers and Self-Rationalisation](https://liu.diva-portal.org/smash/record.jsf?dswid=-2318&pid=diva2%3A1848043). \[[PDF](https://liu.diva-portal.org/smash/get/diva2:1848043/FULLTEXT01.pdf)\]

<!--
  vim:ic noet norl wrap sw=8 ts=8 sts=8 ft=markdown:
  -->
