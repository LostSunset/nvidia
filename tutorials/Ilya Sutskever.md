
# [Ilya Sutskever 的機器學習推薦清單](https://arc.net/folder/D0472A20-9C20-4D3F-B145-D2865C0A9FEE)

> If you really learn all of these, you'll know 90% of what matters today.\
> via: <https://twitter.com/keshavchan/status/1787861946173186062>

 -  [The Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/)
 -  [The First Law of Complexodynamics](https://scottaaronson.blog/?p=762)
 -  [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)
 -  [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
 -  [Recurrent Neural Network Regularization](https://arxiv.org/abs/1409.2329)
 -  [Keeping Neural Networks Simple by Minimizing the Description Length of the Weights](https://www.cs.toronto.edu/~hinton/absps/colt93.pdf)
 -  [Pointer Networks](https://arxiv.org/abs/1506.03134)
 -  [ImageNet Classification with Deep Convolutional Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)
 -  [Order Matters: Sequence to sequence for sets](https://arxiv.org/abs/1511.06391)
 -  [GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism](https://arxiv.org/abs/1811.06965)
 -  [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)
 -  [Multi-Scale Context Aggregation by Dilated Convolutions](https://arxiv.org/abs/1511.07122)
 -  [Neural Message Passing for Quantum Chemistry](https://arxiv.org/abs/1704.01212)
 -  [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
 -  [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)
 -  [Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027)
 -  [A simple neural network module for relational reasoning](https://arxiv.org/abs/1706.01427)
 -  [Variational Lossy Autoencoder](https://arxiv.org/abs/1611.02731)
 -  [Relational recurrent neural networks](https://arxiv.org/abs/1806.01822)
 -  [Quantifying the Rise and Fall of Complexity in Closed Systems: The Coffee Automaton](https://arxiv.org/abs/1405.6903)
 -  [Neural Turing Machines](https://arxiv.org/abs/1410.5401)
 -  [Deep Speech 2: End-to-End Speech Recognition in English and Mandarin](https://arxiv.org/abs/1512.02595)
 -  [Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361)
 -  [A tutorial introduction to the minimum description length principle](https://arxiv.org/abs/math/0406077)
 -  [Machine Super Intelligence](https://www.vetta.org/documents/Machine_Super_Intelligence.pdf)
 -  [Kolmogorov Complexity and Algorithmic Randomness](https://www.lirmm.fr/~ashen/kolmbook-eng-scan.pdf)
 -  [CS231n Convolutional Neural Networks for Visual Recognition](https://cs231n.github.io/)

<!--
  vim:ic noet norl wrap sw=8 ts=8 sts=8 ft=markdown:
  -->
